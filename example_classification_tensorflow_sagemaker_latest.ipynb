{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model Training with TensorFlow in Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows you how to train an image classification model that can be deployed onto our FireFly-DL cameras. We use SageMaker as our training environment, which allows users to train a model on AWS’s cloud platform. In this tutorial we use the Flowers dataset as an example dataset to train a model that can classify five different types of flowers. However, you can choose to upload your own dataset to your S3 bucket and train your classification model on that dataset using this notebook as well.\n",
    "\n",
    "By using SageMaker TensorFlow container we leverage several key functionalities.\n",
    "1.\tAllows us to use our custom script to specify the model architecture (*TF-Slim MobileNet_V1* in this case) that is compatible with the FireFly-DL cameras. In addition, we can leverage Transfer Learning by initializing our model using ImageNet weights.\n",
    "2.\tWe can pass our training script as an argument to the *sagemaker.tensorflow.TensorFlow* method to create an estimator object, which we can call the .fit method on to start the training process.\n",
    "3.\tWe can finally generate a model artifact (trained model) that you can download and convert directly using our NeuroUtility tool, which then can be deployed to our FireFly-DL cameras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we import Sagemaker, TensorFlow and several other python libraries needed in this tuturial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AWS SageMaker python SDK\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "\n",
    "# Additionl libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import urllib\n",
    "import boto3\n",
    "\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We will set up a few things before starting the workflow.\n",
    "1.\tCreate your cloud storage bucket on S3 and assign the name to the variable bucket_name in the code block below.\n",
    "2.\tGet the execution role for accessing your AWS resources, such as, your S3 bucket and GPU instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'firefly-flowers' # MUST PROVIDE BUCKET NAME\n",
    "\n",
    "# check if bucket exists\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "\n",
    "if bucket_name not in buckets:\n",
    "    print(f' S3 bucket name \"{bucket_name}\" does not exists.')\n",
    "else:\n",
    "    print(f' S3 bucket name \"{bucket_name}\" found.')\n",
    "    \n",
    "sess = sagemaker.Session() # initiolize a sagemaker session\n",
    "role = sagemaker.get_execution_role() # we are using the notebook instance role for training in this example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Flowers Dataset \n",
    "\n",
    "Here we provide an example image dataset of five different types of flowers. This section is optional, and if you have your own dataset you can skip ahead to Option 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and Extract Flower Dataset\n",
    "As an example; we will use the Oxford Flowers dataset to train our model. This dataset can be downloaded from the following link http://download.tensorflow.org/example_images/flower_photos.tgz.\n",
    "The flower images are annotated using the parent directory name, and are split between five classes/folders according to the flower type:\n",
    "1. Daisy\n",
    "2. Sunflowers\n",
    "3. Roses\n",
    "4. Tulips\n",
    "5. Dandelion\n",
    "\n",
    "The following code downloads the flower photos and extracts the content to the *'/flower_photos'* directory in your current Jupyter notebook instance.\n",
    "current Jupyter notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(url, data_dir, download_dir):\n",
    "    target_file = url.split('/')[-1]\n",
    "    if target_file not in os.listdir(download_dir):\n",
    "        print('Downloading', url)\n",
    "        urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n",
    "        tf = tarfile.open(url.split('/')[-1])\n",
    "        tf.extractall(data_dir)\n",
    "    else:\n",
    "        print('Already downloaded', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'flower_photos' # Path to image directory folder. This must point to parent directery of the class folders.\n",
    "\n",
    "flowers_url = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "download_and_extract(flowers_url, './', '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visulization Flower Dataset\n",
    "\n",
    "The code below loops over the downloaded image dataset and randomly display’s some the images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "dirs = [f for f in os.listdir(image_dir) if '.txt' not in f]\n",
    "print('list of class labels', dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all images\n",
    "file_list = list()\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            #print(root, file)\n",
    "            file_list.append((root,file))\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 2\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_path =random.choice([os.path.join(root,file) for root, file in file_list])\n",
    "    img = Image.open(img_path, 'r').convert('RGB')\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    ax.title.set_text(img_path.split('/')[-2])\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload Training Images to Your S3 bucket\n",
    "\n",
    "Next, we upload the training images to your S3 cloud storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all bucket names from the response\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "\n",
    "if bucket_name in buckets:\n",
    "    print('Uploading data to S3')\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=bucket_name,\n",
    "                Prefix =image_dir,\n",
    "                MaxKeys=10)\n",
    "    # print(response)\n",
    "    if 'Contents' not in list(response.keys()):\n",
    "        s3_data_path = sess.upload_data(path=image_dir, bucket=bucket_name, key_prefix=image_dir)\n",
    "    else:\n",
    "        s3_data_path = f's3://{bucket_name}/{image_dir}' \n",
    "    print('Uploaded to', s3_data_path)\n",
    "else:\n",
    "    print(f' S3 bucket name \"{bucket_name}\" does not exists.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can skip Option 2 if you wish and go directly to *Train with TensorFlow Estimator* section if you want to train the model on the flowers dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Prepare and Upload Your Own Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Collect Your Own Data\n",
    "\n",
    "First, you must collect and label some images that you would like to use to train the classification model on. \n",
    "1. Collect training images. \n",
    "    * The train.py script only supports the following image formats *'jpg', 'jpeg', 'png', and 'bmp'*.\n",
    "\n",
    "\n",
    "2. Label the images into classes using the parent directory name.\n",
    "    * Each image most be save into only one folder (representing the class)\n",
    "    * The ground-truth label for each image is taken from the parent directory name.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "S3 bucket Directory Structure:\n",
    "\n",
    "bucket_name\n",
    "|\n",
    "|-- image_dir\n",
    "    |\n",
    "    |-- class_1\n",
    "    |   |\n",
    "    |   |--image_1.jpg\n",
    "    |   |--image_2.jpg\n",
    "    |           :\n",
    "    |           :\n",
    "    |-- class_2\n",
    "    |   |\n",
    "    |   |--image_1.jpg\n",
    "    |   |--image_2.jpg\n",
    "    |           :\n",
    "    |           :\n",
    "    |-- class_3\n",
    "    |   |\n",
    "    |   |--image_1.jpg\n",
    "    |   |--image_2.jpg\n",
    "    |           :\n",
    "                :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Upload Training Images to Your S3 Bucket\n",
    " \n",
    "Next, upload your training images directly to the S3 bucket.\n",
    "1.\tCreate a folder (*image_dir*) inside your S3 bucket (*bucket_name*).\n",
    "2.\tAll the class folder (e.g. class_1, class_2 ...), which contain the images must be uploaded under the *image_dir* folder.\n",
    "\n",
    "**Important Note:**\n",
    "Verify that the bucket (*bucket_name*) and image folder (*image_dir*) variable names match the S3 bucket and image folder names, where your images were uploaded to. The above diagram shows the expected S3 image folder and file structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'flower_photos' # MUST PROVIDE CORRECT IMAGE FOLDER NAME\n",
    "\n",
    "s3_data_path = f's3://{bucket_name}/{image_dir}' \n",
    "print('s3 image path', s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tRun the next code block to check your S3 bucket folder structure is correct. If the folder structure is correct, the code output's a list of classes and the number of images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a list of all bucket names from the response\n",
    "def check_s3_response(response, dic):\n",
    "    if 'correct_image_format' not in dic.keys() and 'wrong_image_format' not in dic.keys():\n",
    "        dic = {'correct_image_format':{}, 'wrong_image_format':list()}\n",
    "        \n",
    "    for key in response['Contents']:\n",
    "#         print(key['Key'].split('/'))\n",
    "        # Create file path list\n",
    "        file_path_list = key['Key'].split('/')\n",
    "        # check images\n",
    "        if len(file_path_list) > 2:\n",
    "            if file_path_list[-1].split('.')[1] in ['jpg', 'jpeg', 'png','bmp']:\n",
    "                # check class exists and append image to list\n",
    "                if file_path_list[-2] not in dic['correct_image_format'].keys():\n",
    "                    dic['correct_image_format'][file_path_list[-2]] = list()\n",
    "                dic['correct_image_format'][file_path_list[-2]].append(file_path_list[-1])\n",
    "            else:\n",
    "                dic['correct_image_format'].append('/'.join(file_path_list))\n",
    "    return dic\n",
    "\n",
    "print(f\"Scanning S3 bucket '{s3_data_path}' for images \\n\")\n",
    "\n",
    "# Get a list of all bucket names from the response\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "\n",
    "if bucket_name in buckets:\n",
    "    response = s3.list_objects_v2(\n",
    "                Bucket=bucket_name,\n",
    "                Prefix =image_dir,\n",
    "                MaxKeys=1000)\n",
    "    # print(response)\n",
    "    if 'Contents' in list(response.keys()):\n",
    "        dic = {}\n",
    "        dic = check_s3_response(response, dic)    \n",
    "        while(response['IsTruncated']):\n",
    "            response = s3.list_objects_v2(\n",
    "                    Bucket=bucket_name,\n",
    "                    Prefix=image_dir,\n",
    "                    ContinuationToken=response['NextContinuationToken'],\n",
    "                    MaxKeys=1000)\n",
    "        #         print(response)         \n",
    "            dic = check_s3_response(response, dic)\n",
    "        print(f\"Class folders found in {image_dir} {list(dic['correct_image_format'].keys())}\")\n",
    "        print('Number of images found in each class')\n",
    "        for class_dir in dic['correct_image_format'].keys():\n",
    "            num_images = len(dic['correct_image_format'][class_dir])\n",
    "            print(f'{class_dir}: {num_images}')\n",
    "    else:\n",
    "        s3_data_path = ''\n",
    "        print(f\"'{image_dir}' does not exists in '{bucket_name}' s3 bucket\")\n",
    "        \n",
    "else:\n",
    "    print(f' S3 bucket name \"{bucket_name}\" does not exists.')\n",
    "    s3_data_path = ''\n",
    "\n",
    "print('\\n')\n",
    "print(f'S3 image path set to {s3_data_path}')\n",
    "\n",
    "## TODO:  Visulize random samples of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with TensorFlow Estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train.py Script\n",
    "The training script used in this tutorial was adapted from *TensorFlow for Poets* classification example. We have modified it to handle the parameters passed in by SageMaker. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare for training job\n",
    "\n",
    "1.\tImport Sagemaker TensorFlow python libraries.\n",
    "2.\tSpecify the model hyper-parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparameters = {\n",
    "    # Model backbone architecture\n",
    "    'architecture':'mobilenet_0.25_224',\n",
    "    'feature_vector':'L-2',\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 2000, \n",
    "    'learning_rate': 0.001,\n",
    "    'testing_percentage':10,\n",
    "    'validation_percentage':10,\n",
    "    'train_batch_size':128,\n",
    "    'test_batch_size':-1,\n",
    "    'validation_batch_size':-1,\n",
    "    'final_tensor_name':'final_result',\n",
    "    \n",
    "    # Image Augmentation \n",
    "    'flip_left_right':False,\n",
    "    'flip_up_down':False,\n",
    "    'random_rotate':10,\n",
    "    'random_brightness':10,\n",
    "    'random_scale':10,   \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a training job using the TensorFlow estimator\n",
    "The sagemaker.tensorflow.TensorFlow estimator method handles locating the script mode container, uploading your script to your S3 bucket location, and creating a Sagemaker training job. Below we describe some of the important input arguments for the estimator method.\n",
    "* entry_point is set to 'train.py' which is our training script located in our current instance root directory.\n",
    "* py_version is set to 'py3' to indicate that we are using script mode\n",
    "* framework_version is set to '1.13' to indicate what Tensorflow version we are using.\n",
    "* train_instance_type is set to 'ml.p2.xlarge' which is a type of GPU instance that we will use to train our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f's3://{bucket_name}/'\n",
    "blocks_estimator = TensorFlow(\n",
    "    entry_point='train.py',\n",
    "    role=role,\n",
    "    train_instance_type='ml.p2.xlarge',\n",
    "    train_instance_count=1,\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version='1.13',\n",
    "    py_version='py3',\n",
    "    output_path=output_path\n",
    ")\n",
    "\n",
    "print('The output trained model will save to the following s3 bucket', output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Start the training job\n",
    "\n",
    "We call estimator.fit(s3://...) to start our training job with the S3 location as input argument.\n",
    "\n",
    "When training starts, the TensorFlow container executes the train.py script passing in the hyper-parameters and S3 path (*model_dir*) argument. The training script will print out the training and evaluation accuracies at each epoch. In addition, if you specify a test set percentage the script will produce a test accuracy at the end of the training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training images s3 path: {s3_data_path}')\n",
    "blocks_estimator.fit(s3_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Job Cost Estimate\n",
    "\n",
    "For a typical training job the total cost is split mainly between:\n",
    "1.\tData storage and access costs.\n",
    "2.\tModel training cost. For example an ml.p2.xlarge (GPU) instance type costs 1.26 USD per hour (majority of the cost).\n",
    "3.\tRunning the current Notebook instance.\n",
    "You can use the code block below to estimate the total cost. Copy the *Billable seconds* amount that is printed out at the end of the training process to the variable *Billable_time_in_seconds*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Billable_time_in_seconds = 137 # Enter the bilable time in seconds\n",
    "print(f'Training cost ${Billable_time_in_seconds * 1.26 / 3600}') # $1.26 per hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy The TensorFlow Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the trained model artifact from your S3 bucket.\n",
    "\n",
    "\n",
    "After training is complete Sagemaker automatically compresses and copies the trained model artifact (*model.tar.gz*) to your S3 bucket. Please note the following:\n",
    "* The trained model artifact is saved under the following directory path *s3://bucket_name/tensorflow-training-... /output/* (e.g. s3://firefly-flowers/tensorflow-training-2020-07-03-20-50-48-055/output).\n",
    "* Select the compressed file (*model.tar.gz*) in your S3 console and click the download button to download the file.\n",
    "* Decompress the file using your preferred file decompression tool. Inside the model folder you should find the trained model protbuf file (.pb).\n",
    "\n",
    "### Use NeuroUtility to freeze and convert your model\n",
    "\n",
    "\n",
    "Please take note of the following model parameters when using NeuroUtility. These settings can be found under the *Tensorflow Network Configuration* tab.\n",
    "* The Network Input Width and Height is dependent on the type of model architecture set before training. For our example, because we use mobilenet_0.25_224 model architecture, we set the Network Input Width and the Network Input Height to 224.\n",
    "* Input Layer Name parameter is by default defined in the training script as *input*.\n",
    "* Output Layer Name parameter is by default defined in the training script as *final_result*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
